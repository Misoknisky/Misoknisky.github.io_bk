I"ÁL<ul id="markdown-toc">
  <li><a href="#tensorflow-æ¢¯åº¦è®¡ç®—" id="markdown-toc-tensorflow-æ¢¯åº¦è®¡ç®—">Tensorflow æ¢¯åº¦è®¡ç®—</a></li>
  <li><a href="#compute_gradients" id="markdown-toc-compute_gradients">compute_gradients()</a></li>
</ul>

<p>tensorflow æ˜¯ç›®å‰æ¯”è¾ƒæµè¡Œçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œé™åˆ¶ä¸æˆ‘ä»¬çš„è®¾å¤‡é—®é¢˜ï¼Œåœ¨ä½¿ç”¨å¤§æ•°æ®è®­ç»ƒæ¨¡å‹çš„æ—¶å€™å‘ç°éœ€è¦ç”¨åˆ°æ¢¯åº¦ç´¯ç§¯æŠ€æœ¯å’ŒGPUå¹¶è¡Œè®¡ç®—çš„æŠ€æœ¯ï¼ŒGPUå¹¶è¡Œçš„æ–¹å¼åœ¨tensorflowçš„é«˜é˜¶API estimatorä¸­æœ‰æä¾›ï¼Œä½†æ˜¯å¯¹äºåˆå­¦è€…æ¥è¯´å¯èƒ½å¹¶ä¸äº†è§£Estimator APIï¼Œè¿™é‡Œç»™å‡ºä¸€èˆ¬æƒ…å†µä¸‹ï¼ˆä¸å®ç”¨estimator)å¦‚ä½•è¿›è¡Œå¹¶è¡Œå’Œæ¢¯åº¦ç´¯ç§¯ï¼Œè¿™é‡Œä»‹ç»çš„å¹¶è¡Œæ˜¯æ•°æ®å¹¶è¡Œï¼Œç›¸å…³æ¦‚å¿µå¯ä»¥è‡ªè¡Œç™¾åº¦</p>
<h3 id="tensorflow-æ¢¯åº¦è®¡ç®—">Tensorflow æ¢¯åº¦è®¡ç®—</h3>
<p>æ¢¯åº¦å‡½æ•°minimizeå®é™…ä¸Šè°ƒç”¨äº†ä¸¤ä¸ªå‡½æ•°compute_gradientsã€apply_gradientsï¼Œå‰è€…è´Ÿè´£è®¡ç®—æ¢¯åº¦ï¼Œåè€…è´Ÿè´£è¿›è¡Œæ¢¯åº¦æ›´æ–°ï¼Œä¸ºäº†å¼€å‘è€…å¯ä»¥å¯¹æ¢¯åº¦è¿›è¡Œä¸€å®šçš„æ“ä½œï¼ˆæ¯”å¦‚è£å‰ªï¼‰tensorflowæä¾›äº†minimizeå‡½æ•°çš„åŒæ—¶ä¹Ÿæä¾›äº†compute_gradientsã€apply_gradientså‡½æ•°ï¼Œæ–¹ä¾¿æˆ‘ä»¬çµæ´»ä½¿ç”¨ã€‚
 ä»¥ä¸‹æ˜¯minimize å‡½æ•°çš„æºç è¯´æ˜ï¼Œä¾›å‚è€ƒ</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def minimize(self, loss, global_step=None, var_list=None,
               gate_gradients=GATE_OP, aggregation_method=None,
               colocate_gradients_with_ops=False, name=None,
               grad_loss=None):
    """Add operations to minimize `loss` by updating `var_list`.

    This method simply combines calls `compute_gradients()` and
    `apply_gradients()`. If you want to process the gradient before applying
    them call `compute_gradients()` and `apply_gradients()` explicitly instead
    of using this function.

    Args:
      loss: A `Tensor` containing the value to minimize.
      global_step: Optional `Variable` to increment by one after the
        variables have been updated.
      var_list: Optional list or tuple of `Variable` objects to update to
        minimize `loss`.  Defaults to the list of variables collected in
        the graph under the key `GraphKeys.TRAINABLE_VARIABLES`.
      gate_gradients: How to gate the computation of gradients.  Can be
        `GATE_NONE`, `GATE_OP`, or  `GATE_GRAPH`.
      aggregation_method: Specifies the method used to combine gradient terms.
        Valid values are defined in the class `AggregationMethod`.
      colocate_gradients_with_ops: If True, try colocating gradients with
        the corresponding op.
      name: Optional name for the returned operation.
      grad_loss: Optional. A `Tensor` holding the gradient computed for `loss`.

    Returns:
      An Operation that updates the variables in `var_list`.  If `global_step`
      was not `None`, that operation also increments `global_step`.

    Raises:
      ValueError: If some of the variables are not `Variable` objects.
</code></pre></div></div>

<h3 id="compute_gradients">compute_gradients()</h3>

<p>ä¸€ä¸‹æ˜¯compute_gradientså‡½æ•°çš„æºç è¯´æ˜ï¼Œä¾›å‚è€ƒ</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def compute_gradients(self, loss, var_list=None,
                        gate_gradients=GATE_OP,
                        aggregation_method=None,
                        colocate_gradients_with_ops=False,
                        grad_loss=None):
    """Compute gradients of `loss` for the variables in `var_list`.

    This is the first part of `minimize()`.  It returns a list
    of (gradient, variable) pairs where "gradient" is the gradient
    for "variable".  Note that "gradient" can be a `Tensor`, an
    `IndexedSlices`, or `None` if there is no gradient for the
    given variable.

    Args:
      loss: A Tensor containing the value to minimize or a callable taking
        no arguments which returns the value to minimize. When eager execution
        is enabled it must be a callable.
      var_list: Optional list or tuple of `tf.Variable` to update to minimize
        `loss`.  Defaults to the list of variables collected in the graph
        under the key `GraphKeys.TRAINABLE_VARIABLES`.
      gate_gradients: How to gate the computation of gradients.  Can be
        `GATE_NONE`, `GATE_OP`, or `GATE_GRAPH`.
      aggregation_method: Specifies the method used to combine gradient terms.
        Valid values are defined in the class `AggregationMethod`.
      colocate_gradients_with_ops: If True, try colocating gradients with
        the corresponding op.
      grad_loss: Optional. A `Tensor` holding the gradient computed for `loss`.

    Returns:
      A list of (gradient, variable) pairs. Variable is always present, but
      gradient can be `None`.
</code></pre></div></div>
<p>å¯ä»¥å‘ç°compute_gradientså‡½æ•°è¿”å›çš„æ˜¯æ¢¯åº¦å¯¹[(gradient1, variable1),(gradient2, variable2),â€¦]ï¼Œgradient è¡¨ç¤ºçš„æ¢¯åº¦å€¼ï¼Œvariableè¡¨ç¤ºçš„æ˜¯å˜é‡ï¼Œä¹Ÿå°±æ˜¯è¯¥å˜é‡variableçš„æ¢¯åº¦æ˜¯gradientã€‚é™¤æ­¤ä¹‹å¤–æ¢¯åº¦å¯èƒ½å‡ºç°æ²¡æœ‰æ¢¯åº¦çš„æƒ…å†µå³æ¢¯åº¦ä¸º Noneï¼Œå®é™…æƒ…å†µä¸‹åœ¨æ¨¡å‹ä¸­è®¡ç®—å‡ºæ¥çš„æ¢¯åº¦æ˜¯ä»€ä¹ˆæ ·å­çš„å‘¢ï¼Œä»¥ä¸‹ç»™å‡ºä¸€ä¸ªæ ·ä¾‹(gradient, variable)ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>IndexedSlices(indices=Tensor("model/gradients/concat_1:0", shape=(?,), dtype=int32, device=/device:GPU:3), values=Tensor("model/gradients/concat:0", shape=(?, 300), dtype=float32, device=/device:GPU:3), dense_shape=Tensor("model/gradients/model/word_embedding/embedding_lookup_grad/ToInt32:0", shape=(2,), dtype=int32, device=/device:CPU:0)) &lt;tf.Variable 'model/word_embedding/word_embeddings:0' shape=(45438, 300) dtype=float32_ref&gt;
Tensor("model/gradients/model/passage_encoding/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul/Enter_grad/b_acc_3:0", shape=(450, 600), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/passage_encoding/bidirectional_rnn/fw/lstm_cell/kernel:0' shape=(450, 600) dtype=float32_ref&gt;
Tensor("model/gradients/model/passage_encoding/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd/Enter_grad/b_acc_3:0", shape=(600,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/passage_encoding/bidirectional_rnn/fw/lstm_cell/bias:0' shape=(600,) dtype=float32_ref&gt;
Tensor("model/gradients/model/passage_encoding/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul/Enter_grad/b_acc_3:0", shape=(450, 600), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/passage_encoding/bidirectional_rnn/bw/lstm_cell/kernel:0' shape=(450, 600) dtype=float32_ref&gt;
Tensor("model/gradients/model/passage_encoding/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd/Enter_grad/b_acc_3:0", shape=(600,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/passage_encoding/bidirectional_rnn/bw/lstm_cell/bias:0' shape=(600,) dtype=float32_ref&gt;
Tensor("model/gradients/model/question_encoding/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul/Enter_grad/b_acc_3:0", shape=(450, 600), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/question_encoding/bidirectional_rnn/fw/lstm_cell/kernel:0' shape=(450, 600) dtype=float32_ref&gt;
Tensor("model/gradients/model/question_encoding/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd/Enter_grad/b_acc_3:0", shape=(600,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/question_encoding/bidirectional_rnn/fw/lstm_cell/bias:0' shape=(600,) dtype=float32_ref&gt;
Tensor("model/gradients/model/question_encoding/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul/Enter_grad/b_acc_3:0", shape=(450, 600), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/question_encoding/bidirectional_rnn/bw/lstm_cell/kernel:0' shape=(450, 600) dtype=float32_ref&gt;
Tensor("model/gradients/model/question_encoding/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd/Enter_grad/b_acc_3:0", shape=(600,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/question_encoding/bidirectional_rnn/bw/lstm_cell/bias:0' shape=(600,) dtype=float32_ref&gt;
Tensor("model/gradients/model/fusion/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul/Enter_grad/b_acc_3:0", shape=(1350, 600), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/fusion/bidirectional_rnn/fw/lstm_cell/kernel:0' shape=(1350, 600) dtype=float32_ref&gt;
Tensor("model/gradients/model/fusion/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd/Enter_grad/b_acc_3:0", shape=(600,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/fusion/bidirectional_rnn/fw/lstm_cell/bias:0' shape=(600,) dtype=float32_ref&gt;
Tensor("model/gradients/model/fusion/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul/Enter_grad/b_acc_3:0", shape=(1350, 600), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/fusion/bidirectional_rnn/bw/lstm_cell/kernel:0' shape=(1350, 600) dtype=float32_ref&gt;
Tensor("model/gradients/model/fusion/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd/Enter_grad/b_acc_3:0", shape=(600,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/fusion/bidirectional_rnn/bw/lstm_cell/bias:0' shape=(600,) dtype=float32_ref&gt;
Tensor("model/gradients/model/fusion/gated_layer/dense/MatMul_grad/tuple/control_dependency_1:0", shape=(300, 300), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/fusion/gated_layer/dense/W:0' shape=(300, 300) dtype=float32_ref&gt;
Tensor("model/gradients/model/para_attention/self_attention/MatMul_grad/tuple/control_dependency_1:0", shape=(300, 300), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/para_attention/self_attention/W:0' shape=(300, 300) dtype=float32_ref&gt;
Tensor("model/gradients/model/para_attention/bidirectional_rnn/fw/fw/while/gru_cell/MatMul/Enter_grad/b_acc_3:0", shape=(750, 300), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/para_attention/bidirectional_rnn/fw/gru_cell/gates/kernel:0' shape=(750, 300) dtype=float32_ref&gt;
Tensor("model/gradients/model/para_attention/bidirectional_rnn/fw/fw/while/gru_cell/BiasAdd/Enter_grad/b_acc_3:0", shape=(300,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/para_attention/bidirectional_rnn/fw/gru_cell/gates/bias:0' shape=(300,) dtype=float32_ref&gt;
Tensor("model/gradients/model/para_attention/bidirectional_rnn/fw/fw/while/gru_cell/MatMul_1/Enter_grad/b_acc_3:0", shape=(750, 150), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/para_attention/bidirectional_rnn/fw/gru_cell/candidate/kernel:0' shape=(750, 150) dtype=float32_ref&gt;
Tensor("model/gradients/model/para_attention/bidirectional_rnn/fw/fw/while/gru_cell/BiasAdd_1/Enter_grad/b_acc_3:0", shape=(150,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/para_attention/bidirectional_rnn/fw/gru_cell/candidate/bias:0' shape=(150,) dtype=float32_ref&gt;
Tensor("model/gradients/model/para_attention/bidirectional_rnn/bw/bw/while/gru_cell/MatMul/Enter_grad/b_acc_3:0", shape=(750, 300), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/para_attention/bidirectional_rnn/bw/gru_cell/gates/kernel:0' shape=(750, 300) dtype=float32_ref&gt;
Tensor("model/gradients/model/para_attention/bidirectional_rnn/bw/bw/while/gru_cell/BiasAdd/Enter_grad/b_acc_3:0", shape=(300,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/para_attention/bidirectional_rnn/bw/gru_cell/gates/bias:0' shape=(300,) dtype=float32_ref&gt;
Tensor("model/gradients/model/para_attention/bidirectional_rnn/bw/bw/while/gru_cell/MatMul_1/Enter_grad/b_acc_3:0", shape=(750, 150), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/para_attention/bidirectional_rnn/bw/gru_cell/candidate/kernel:0' shape=(750, 150) dtype=float32_ref&gt;
Tensor("model/gradients/model/para_attention/bidirectional_rnn/bw/bw/while/gru_cell/BiasAdd_1/Enter_grad/b_acc_3:0", shape=(150,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/para_attention/bidirectional_rnn/bw/gru_cell/candidate/bias:0' shape=(150,) dtype=float32_ref&gt;
Tensor("model/gradients/model/document_attention/self_attention/MatMul_grad/tuple/control_dependency_1:0", shape=(300, 300), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/document_attention/self_attention/W:0' shape=(300, 300) dtype=float32_ref&gt;
Tensor("model/gradients/model/document_attention/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul/Enter_grad/b_acc_3:0", shape=(750, 600), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/document_attention/bidirectional_rnn/fw/lstm_cell/kernel:0' shape=(750, 600) dtype=float32_ref&gt;
Tensor("model/gradients/model/document_attention/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd/Enter_grad/b_acc_3:0", shape=(600,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/document_attention/bidirectional_rnn/fw/lstm_cell/bias:0' shape=(600,) dtype=float32_ref&gt;
Tensor("model/gradients/model/document_attention/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul/Enter_grad/b_acc_3:0", shape=(750, 600), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/document_attention/bidirectional_rnn/bw/lstm_cell/kernel:0' shape=(750, 600) dtype=float32_ref&gt;
Tensor("model/gradients/model/document_attention/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd/Enter_grad/b_acc_3:0", shape=(600,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/document_attention/bidirectional_rnn/bw/lstm_cell/bias:0' shape=(600,) dtype=float32_ref&gt;
Tensor("model/gradients/model/pn_decoder/attend_pooling/ExpandDims_grad/Reshape:0", shape=(1, 150), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/pn_decoder/random_attn_vector:0' shape=(1, 150) dtype=float32_ref&gt;
Tensor("model/gradients/model/pn_decoder/attend_pooling/fully_connected/Tensordot/transpose_1_grad/transpose:0", shape=(300, 150), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/pn_decoder/attend_pooling/fully_connected/weights:0' shape=(300, 150) dtype=float32_ref&gt;
Tensor("model/gradients/model/pn_decoder/attend_pooling/fully_connected_1/Tensordot/transpose_1_grad/transpose:0", shape=(150, 150), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/pn_decoder/attend_pooling/fully_connected_1/weights:0' shape=(150, 150) dtype=float32_ref&gt;
Tensor("model/gradients/model/pn_decoder/attend_pooling/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0", shape=(150,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/pn_decoder/attend_pooling/fully_connected_1/biases:0' shape=(150,) dtype=float32_ref&gt;
Tensor("model/gradients/model/pn_decoder/attend_pooling/fully_connected_2/Tensordot/transpose_1_grad/transpose:0", shape=(150, 1), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/pn_decoder/attend_pooling/fully_connected_2/weights:0' shape=(150, 1) dtype=float32_ref&gt;
Tensor("model/gradients/model/pn_decoder/attend_pooling/fully_connected_2/BiasAdd_grad/tuple/control_dependency_1:0", shape=(1,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/pn_decoder/attend_pooling/fully_connected_2/biases:0' shape=(1,) dtype=float32_ref&gt;
Tensor("model/gradients/model/pn_decoder/fully_connected/MatMul_grad/tuple/control_dependency_1:0", shape=(300, 150), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/pn_decoder/fully_connected/weights:0' shape=(300, 150) dtype=float32_ref&gt;
Tensor("model/gradients/model/pn_decoder/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0", shape=(150,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/pn_decoder/fully_connected/biases:0' shape=(150,) dtype=float32_ref&gt;
Tensor("model/gradients/model/pn_decoder/fw/fully_connected/Tensordot/transpose_1_grad/transpose:0", shape=(300, 150), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/pn_decoder/fw/fully_connected/weights:0' shape=(300, 150) dtype=float32_ref&gt;
Tensor("model/gradients/model/pn_decoder/fw/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0", shape=(150,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/pn_decoder/fw/fully_connected/biases:0' shape=(150,) dtype=float32_ref&gt;
Tensor("model/gradients/model/pn_decoder/fw/while/PointerNetLSTMCell/fully_connected/MatMul/Enter_grad/b_acc_3:0", shape=(150, 150), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/pn_decoder/fw/PointerNetLSTMCell/fully_connected/weights:0' shape=(150, 150) dtype=float32_ref&gt;
Tensor("model/gradients/model/pn_decoder/fw/while/PointerNetLSTMCell/fully_connected/BiasAdd/Enter_grad/b_acc_3:0", shape=(150,), dtype=float32, device=/device:GPU:3) &lt;tf.Variable 'model/pn_decoder/fw/PointerNetLSTMCell/fully_connected/biases:0' shape=(150,) dtype=float32_ref&gt;
</code></pre></div></div>

<p>å¯ä»¥å‘ç°gradientå¤šæ•°æƒ…å†µä¸‹æ˜¯ä¸€ä¸ªTensor,é™¤äº†Tensorå¤–è¿˜æœ‰ä¸€ä¸ªIndexedSlicesç±»å‹ï¼›variableæ€»æ˜¯ä¸€ä¸ªtf.Variableç±»å‹ï¼›æ­£å¸¸æƒ…å†µä¸‹è®¡ç®—ä¸€ä¸ªbatchçš„æ¢¯åº¦æ›´æ–°ä¸€æ¬¡ï¼Œç°åœ¨æˆ‘ä»¬ä¸æƒ³é©¬ä¸Šæ›´æ–°æ¢¯åº¦ï¼Œå¸Œæœ›ç´¯ç§¯åˆ°ä¸€å®šæ­¥æ•°æ›´æ–°ä¸€æ¬¡ï¼›æ­£å¸¸çš„æ€è·¯å°±æ˜¯å°†æ‰€æœ‰ç´¯ç§¯çš„æ¢¯åº¦ä½¿ç”¨ä¸€ä¸ªå˜é‡è¿›è¡Œä¿å­˜ï¼Œç„¶åæ›´æ–°ï¼Œè¿™é‡Œå°±éœ€è¦å°†æ¢¯åº¦è®¡ç®—å’Œæ›´æ–°åˆ†å¼€æ¥åšã€‚ tensorflowåœ¨2.0ä¹‹å‰æ˜¯é™æ€å›¾ï¼Œé™æ€å›¾å°†ç´¯ç§¯çš„æ¢¯åº¦å›ä¼ çš„æ–¹å¼å°±æ˜¯é€šè¿‡feedæœºåˆ¶ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦çš„æ¢¯åº¦å‚¨å­˜å™¨æ˜¯ä¸€ä¸ªplaceholderå ä½ç¬¦å¦‚ä½•åˆ›å»ºï¼Ÿvariableè¡¨æ­»çš„æ˜¯è®¡ç®—å›¾çš„èŠ‚ç‚¹ï¼Œå½“å›¾ç¡®å®šåè®¡ç®—å›¾çš„èŠ‚ç‚¹æ˜¯ä¸å˜çš„ï¼Œå®ƒè¡¨ç¤ºçš„æ˜¯èŠ‚ç‚¹çš„åç§°ï¼Œæˆ‘ä»¬ä¹‹è¦å°†ç´¯è®¡çš„æ¢¯åº¦å€¼å’ŒèŠ‚ç‚¹ä¸€ä¸€å¯¹åº”ä¸Šå³å¯ï¼Œæ‰€ä»¥å¯¹Variable ä¸éœ€è¦ç´¯ç§¯ï¼Œåªéœ€è¦æŠŠæ¢¯åº¦å€¼è¿›è¡Œç´¯è®¡å³å¯ï¼›å¯¹äºtensorç±»å‹çš„gradientï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>grads_holede=[]
grads_holede.append((tf.placeholder(dtype=g.dtype, shape=g.get_shape()), v))
</code></pre></div></div>
<p>æŒ‰ä»¥ä¸Šæ–¹å¼åˆ›å»ºæ¢¯åº¦æ¥æ”¶å™¨ï¼Œæ¢¯åº¦çš„å½¢å¼å¿…é¡»å’ŒåŸæ¥ä¿æŒä¸€è‡´ï¼Œå› æ­¤è¿™é‡Œå°è£…çš„æ˜¯(gradient,Variable) çš„å…ƒç»„ã€‚ä¹‹ååªéœ€å°†æ±‚å¾—çš„æ¢¯åº¦ç´¯ç§¯æ±‚å’Œfeedç»™æ¢¯åº¦æ¥æ”¶å™¨è¿›è¡Œæ›´æ–°å³å¯ã€‚</p>

<p>å¯¹äºgradientä¸ºIndexedSlicesç±»å‹æ¯”è¾ƒéº»çƒ¦ä¸€äº›ï¼ŒIndexedSlicesç±»å‹æ˜¯ä¸€ä¸ªç¨€ç–çŸ©é˜µï¼Œæ˜¯å› ä¸ºæŸ¥embeddingè¡¨æ“ä½œäº§ç”Ÿçš„ï¼Œå¯ä»¥çœ‹å‡ºæ‰€æœ‰çš„æ¢¯åº¦ä¸­åªç»´æŠ¤äº†ä¸€ä¸ªIndexedSlicesç±»å‹ï¼Œè€Œå®é™…ä¸Šç¨‹åºä¸­æœ‰ä¸¤ä¸ªæŸ¥è¡¨æ“ä½œï¼ˆæˆ‘çš„ç¨‹åºæ˜¯è¿™ä¹ˆå†™çš„ï¼‰ï¼Œç ”ç©¶å‘ç°è¿™ä¸ªIndexedSliceså˜é‡æ‹¼æ¥äº†æ‰€æœ‰äº§ç”Ÿçš„ç¨€ç–çŸ©é˜µï¼›IndexedSlices æœ‰ä¸‰ä¸ªå€¼indicesã€valuesã€dense_shapeï¼Œå…¶ä¸­indicesè¡¨ç¤ºéœ€è¦æ›´æ–°çš„embeddingè¡¨å¯¹åº”çš„è¡Œï¼Œvalueså’Œindicesä¸€ä¸€å¯¹åº”ä»£è¡¨æŸ¥è¡¨è·å–çš„ç›¸åº”çš„embedding è¡¨ç¤ºï¼Œdense_shapeè¡¨ç¤ºçš„æ˜¯æ•´ä¸ªembeddingè¡¨çš„å¤§å°ï¼Œå’ŒIndexedSliceså¯¹åº”çš„Variableå°±æ˜¯embeddingèŠ‚ç‚¹åç§°ã€‚å¯ä»¥å‘ç°IndexedSlices é‡Œçš„indicesã€valuesã€dense_shapeéƒ½æ˜¯tensorå› æ­¤éƒ½éœ€è¦åˆ›å»ºå¯¹åº”çš„æ¥å—å™¨ï¼Œç„¶åå†å°è£…æˆIndexedSlicesï¼Œå°†å°è£…åçš„IndexedSlicesä½œä¸ºgradientä¸å¯¹åº”çš„Variableä¸€èµ·æ„æˆæ¢¯åº¦å…ƒç»„ã€‚å…·ä½“çš„å¦‚ä¸‹ï¼š</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>IndexedSlices_index = tf.placeholder(dtype=tf.int32,shape=g.indices.shape)
IndexedSlices_value = tf.placeholder(dtype=g.values.dtype,shape=g.values.shape)
IndexedSlices_Dense_shape = tf.placeholder(dtype=g.dense_shape.dtype, shape=g.dense_shape.shape)
grade_IndexedSlices=tf.IndexedSlices(self.IndexedSlices_value,
                                                     self.IndexedSlices_index,
                                                     dense_shape=self.IndexedSlices_Dense_shape)
grads_holder.append((grade_IndexedSlices,v))
</code></pre></div></div>
:ET